{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Processing:\n",
        "## Takes two datasets (OpenBCI data & and Keylogger), cleans, merges based on timestamp, and exports individual .csv files for each class."
      ],
      "metadata": {
        "id": "EqAfSrWA3gEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "k3_meb7PAEWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "9-E0q8xYxCUT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "6BOIXedl_-e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "header_row_number = 4\n",
        "data = pd.read_csv('/content/OpenBCI-RAW-2024-03-08_10-40-02.txt', on_bad_lines='warn', header=header_row_number)\n",
        "\n",
        "# Remove the space at the beginning of every header name\n",
        "data = data.rename(columns=lambda x: x.strip())\n",
        "\n",
        "# Load Key logs\n",
        "header_row_number = 0\n",
        "key_logs = pd.read_csv('/content/KEYLOGGER_2024-03-08_10_39_21.csv', on_bad_lines='warn', header=header_row_number)"
      ],
      "metadata": {
        "id": "Oxi4vcmbxZyb"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data"
      ],
      "metadata": {
        "id": "Frb5NHoL_6lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = ['Sample Index',\n",
        "                  'EXG Channel 0',\n",
        "                  'EXG Channel 1',\n",
        "                  'EXG Channel 2',\n",
        "                  'EXG Channel 3',\n",
        "                  'EXG Channel 4',\n",
        "                  'EXG Channel 5',\n",
        "                  'EXG Channel 6',\n",
        "                  'EXG Channel 7',\n",
        "                   'Timestamp (Formatted)']\n",
        "\n",
        "# Remove unnecessary columns\n",
        "data = data[columns_to_keep]\n",
        "# Drop N/A values and count the number of dropped rows\n",
        "dropped_data = data.dropna()\n",
        "dropped_count = len(data) - len(dropped_data)\n",
        "print(f'Dropped {dropped_count} N/A rows')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAgFscd62YyC",
        "outputId": "e1e07542-bfe4-46f7-a30b-65a4dbbd9b6d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 0 N/A rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Datasets"
      ],
      "metadata": {
        "id": "fAUUVJ5ItkeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert timestamps to datetime objects\n",
        "data['Timestamp (Formatted)'] = pd.to_datetime(data['Timestamp (Formatted)'], format='%Y-%m-%d %H:%M:%S')\n",
        "key_logs['Timestamp'] = pd.to_datetime(key_logs['Timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Extract date and time up to seconds\n",
        "data['Timestamp (Formatted)'] = data['Timestamp (Formatted)'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "key_logs['Timestamp'] = key_logs['Timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Merge dataframes based on timestamp\n",
        "merged_data = data.merge(key_logs, left_on='Timestamp (Formatted)', right_on='Timestamp', how='left')\n",
        "\n",
        "# Fill NaN values in the 'Class' column with the last known class\n",
        "merged_data['Class'] = merged_data['Class'].fillna(method='ffill')\n"
      ],
      "metadata": {
        "id": "BF34RV5YtoEq"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtain Final Dataset"
      ],
      "metadata": {
        "id": "PJOfMV7O2WQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the unnecessary 'Timestamp' column\n",
        "final_data = merged_data.drop(columns=['Sample Index', 'Timestamp', 'Timestamp (Formatted)'])\n",
        "\n",
        "# Drop rows with NaN values in the 'Class' column\n",
        "final_data.dropna(subset=['Class'], inplace=True)\n",
        "\n",
        "# Reset the index\n",
        "final_data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "V5ptOqQa0ezA"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Datasets per Class"
      ],
      "metadata": {
        "id": "aQWAfTfq3B_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values in the 'Class' column\n",
        "class_values = final_data['Class'].unique()\n",
        "\n",
        "# Get current date and time\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "# Iterate over unique class values and export to CSV\n",
        "for class_value in class_values:\n",
        "    class_data = final_data[final_data['Class'] == class_value]\n",
        "    class_data = class_data.drop(columns=['Class'])\n",
        "    class_data.to_csv(f'{class_value}_{timestamp}.csv', index=False)"
      ],
      "metadata": {
        "id": "U18b4Ptb3FPZ"
      },
      "execution_count": 87,
      "outputs": []
    }
  ]
}